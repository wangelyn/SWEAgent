"""
å¯¹è¯å¼è½¯ä»¶å¼€å‘ä¸“ç”¨å·¥å…·é›†
"""
import json
import os
from typing import Any, Dict, List, Optional
from datetime import datetime

from app.tool.base import BaseTool
from app.tool.str_replace_editor import StrReplaceEditor
from app.tool.bash import Bash
from app.logger import logger


class ConversationalCodeReview(BaseTool):
    """
    å¯¹è¯å¼ä»£ç å®¡æŸ¥å·¥å…·
    """

    def __init__(self):
        super().__init__(
            name="conversational_code_review",
            description="è¿›è¡Œå¯¹è¯å¼ä»£ç å®¡æŸ¥ï¼Œåˆ†æä»£ç è´¨é‡å¹¶æå‡ºæ”¹è¿›å»ºè®®",
            parameters={
                "type": "object",
                "properties": {
                    "file_path": {
                        "type": "string",
                        "description": "è¦å®¡æŸ¥çš„æ–‡ä»¶è·¯å¾„"
                    },
                    "review_focus": {
                        "type": "string",
                        "description": "å®¡æŸ¥é‡ç‚¹ï¼š'performance'(æ€§èƒ½), 'security'(å®‰å…¨), 'readability'(å¯è¯»æ€§), 'architecture'(æ¶æ„), 'all'(å…¨é¢)",
                        "enum": ["performance", "security", "readability", "architecture", "all"],
                        "default": "all"
                    },
                    "ask_questions": {
                        "type": "boolean",
                        "description": "æ˜¯å¦åœ¨å®¡æŸ¥ä¸­æå‡ºé—®é¢˜ä¾›å¼€å‘è€…æ€è€ƒ",
                        "default": True
                    }
                },
                "required": ["file_path"]
            }
        )

    async def execute(self, file_path: str, review_focus: str = "all", ask_questions: bool = True) -> str:
        """æ‰§è¡Œå¯¹è¯å¼ä»£ç å®¡æŸ¥"""
        try:
            if not os.path.exists(file_path):
                return f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}"

            # è¯»å–æ–‡ä»¶å†…å®¹
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()

            if not content.strip():
                return f"ğŸ“„ æ–‡ä»¶ä¸ºç©º: {file_path}"

            # åˆ†æä»£ç 
            review_result = self._analyze_code(content, file_path, review_focus)

            # ç”Ÿæˆå¯¹è¯å¼å®¡æŸ¥æŠ¥å‘Š
            report = self._generate_conversation_report(review_result, ask_questions)

            return f"ğŸ” ä»£ç å®¡æŸ¥å®Œæˆ: {file_path}\n\n{report}"

        except Exception as e:
            logger.error(f"ä»£ç å®¡æŸ¥å‡ºé”™: {e}")
            return f"âŒ ä»£ç å®¡æŸ¥å¤±è´¥: {str(e)}"

    def _analyze_code(self, content: str, file_path: str, focus: str) -> Dict[str, Any]:
        """åˆ†æä»£ç è´¨é‡"""
        lines = content.split('\n')

        analysis = {
            "file_info": {
                "path": file_path,
                "lines": len(lines),
                "size": len(content),
                "extension": os.path.splitext(file_path)[1]
            },
            "issues": [],
            "suggestions": [],
            "questions": []
        }

        # åŸºç¡€åˆ†æï¼ˆç®€åŒ–ç‰ˆï¼Œå®é™…åº”ç”¨ä¸­å¯é›†æˆé™æ€åˆ†æå·¥å…·ï¼‰
        if focus in ["readability", "all"]:
            analysis = self._check_readability(content, lines, analysis)

        if focus in ["performance", "all"]:
            analysis = self._check_performance(content, lines, analysis)

        if focus in ["security", "all"]:
            analysis = self._check_security(content, lines, analysis)

        if focus in ["architecture", "all"]:
            analysis = self._check_architecture(content, lines, analysis)

        return analysis

    def _check_readability(self, content: str, lines: List[str], analysis: Dict) -> Dict:
        """æ£€æŸ¥ä»£ç å¯è¯»æ€§"""
        # æ£€æŸ¥é•¿è¡Œ
        long_lines = [(i+1, line) for i, line in enumerate(lines) if len(line) > 100]
        if long_lines:
            analysis["issues"].append({
                "type": "readability",
                "severity": "medium",
                "message": f"å‘ç° {len(long_lines)} è¡Œè¶…è¿‡100å­—ç¬¦çš„é•¿è¡Œ",
                "lines": [line_num for line_num, _ in long_lines[:3]]
            })
            analysis["questions"].append("è¿™äº›é•¿è¡Œæ˜¯å¦å¯ä»¥é€šè¿‡é‡æ„æ¥æé«˜å¯è¯»æ€§ï¼Ÿ")

        # æ£€æŸ¥æ³¨é‡Š
        comment_lines = [line for line in lines if line.strip().startswith('#') or line.strip().startswith('//')]
        comment_ratio = len(comment_lines) / len(lines) if lines else 0

        if comment_ratio < 0.1:
            analysis["suggestions"].append({
                "type": "readability",
                "message": "å»ºè®®å¢åŠ ä»£ç æ³¨é‡Šï¼Œå½“å‰æ³¨é‡Šæ¯”ä¾‹è¾ƒä½",
                "action": "æ·»åŠ å…³é”®é€»è¾‘çš„æ³¨é‡Šè¯´æ˜"
            })
            analysis["questions"].append("å“ªäº›å¤æ‚çš„é€»è¾‘éœ€è¦æ·»åŠ æ³¨é‡Šæ¥å¸®åŠ©ç†è§£ï¼Ÿ")

        return analysis

    def _check_performance(self, content: str, lines: List[str], analysis: Dict) -> Dict:
        """æ£€æŸ¥æ€§èƒ½ç›¸å…³é—®é¢˜"""
        # æ£€æŸ¥å¾ªç¯åµŒå¥—
        nested_loops = 0
        loop_depth = 0
        for line in lines:
            stripped = line.strip()
            if stripped.startswith('for ') or stripped.startswith('while '):
                loop_depth += 1
                if loop_depth > 1:
                    nested_loops += 1
            if not line.startswith(' ') and not line.startswith('\t'):
                loop_depth = 0

        if nested_loops > 0:
            analysis["issues"].append({
                "type": "performance",
                "severity": "medium",
                "message": f"å‘ç° {nested_loops} å¤„åµŒå¥—å¾ªç¯",
                "suggestion": "è€ƒè™‘ä¼˜åŒ–ç®—æ³•å¤æ‚åº¦"
            })
            analysis["questions"].append("è¿™äº›åµŒå¥—å¾ªç¯æ˜¯å¦å¯ä»¥é€šè¿‡æ›´é«˜æ•ˆçš„ç®—æ³•æ¥ä¼˜åŒ–ï¼Ÿ")

        return analysis

    def _check_security(self, content: str, lines: List[str], analysis: Dict) -> Dict:
        """æ£€æŸ¥å®‰å…¨é—®é¢˜"""
        security_risks = []

        # æ£€æŸ¥SQLæ³¨å…¥é£é™©
        if 'execute(' in content or 'query(' in content:
            if '%s' in content or '.format(' in content:
                security_risks.append("å¯èƒ½å­˜åœ¨SQLæ³¨å…¥é£é™©")

        # æ£€æŸ¥ç¡¬ç¼–ç å¯†ç 
        if any(keyword in content.lower() for keyword in ['password', 'secret', 'key']):
            if '=' in content:
                security_risks.append("å¯èƒ½å­˜åœ¨ç¡¬ç¼–ç æ•æ„Ÿä¿¡æ¯")

        if security_risks:
            analysis["issues"].extend([{
                "type": "security",
                "severity": "high",
                "message": risk
            } for risk in security_risks])
            analysis["questions"].append("å¦‚ä½•ç¡®ä¿æ•æ„Ÿä¿¡æ¯çš„å®‰å…¨å­˜å‚¨å’Œä¼ è¾“ï¼Ÿ")

        return analysis

    def _check_architecture(self, content: str, lines: List[str], analysis: Dict) -> Dict:
        """æ£€æŸ¥æ¶æ„é—®é¢˜"""
        # æ£€æŸ¥å‡½æ•°é•¿åº¦
        function_lines = []
        current_function_lines = 0
        in_function = False

        for line in lines:
            if line.strip().startswith('def ') or line.strip().startswith('class '):
                if in_function and current_function_lines > 0:
                    function_lines.append(current_function_lines)
                in_function = True
                current_function_lines = 0
            elif in_function:
                current_function_lines += 1

        long_functions = [length for length in function_lines if length > 50]
        if long_functions:
            analysis["suggestions"].append({
                "type": "architecture",
                "message": f"å‘ç° {len(long_functions)} ä¸ªé•¿å‡½æ•°(>50è¡Œ)",
                "action": "è€ƒè™‘å°†é•¿å‡½æ•°åˆ†è§£ä¸ºæ›´å°çš„å‡½æ•°"
            })
            analysis["questions"].append("è¿™äº›é•¿å‡½æ•°æ˜¯å¦æ‰¿æ‹…äº†è¿‡å¤šçš„èŒè´£ï¼Ÿ")

        return analysis

    def _generate_conversation_report(self, analysis: Dict, ask_questions: bool) -> str:
        """ç”Ÿæˆå¯¹è¯å¼å®¡æŸ¥æŠ¥å‘Š"""
        report_parts = []

        # æ–‡ä»¶åŸºæœ¬ä¿¡æ¯
        file_info = analysis["file_info"]
        report_parts.append(f"ğŸ“Š **æ–‡ä»¶æ¦‚è§ˆ**")
        report_parts.append(f"- æ–‡ä»¶: {file_info['path']}")
        report_parts.append(f"- è¡Œæ•°: {file_info['lines']}")
        report_parts.append(f"- å¤§å°: {file_info['size']} å­—ç¬¦")

        # é—®é¢˜æŠ¥å‘Š
        if analysis["issues"]:
            report_parts.append(f"\nâš ï¸  **å‘ç°çš„é—®é¢˜** ({len(analysis['issues'])}ä¸ª)")
            for issue in analysis["issues"]:
                severity_emoji = {"high": "ğŸ”´", "medium": "ğŸŸ¡", "low": "ğŸŸ¢"}.get(issue["severity"], "âšª")
                report_parts.append(f"{severity_emoji} {issue['message']}")
                if "lines" in issue:
                    report_parts.append(f"   ä½ç½®: ç¬¬ {', '.join(map(str, issue['lines']))} è¡Œ")

        # æ”¹è¿›å»ºè®®
        if analysis["suggestions"]:
            report_parts.append(f"\nğŸ’¡ **æ”¹è¿›å»ºè®®** ({len(analysis['suggestions'])}ä¸ª)")
            for suggestion in analysis["suggestions"]:
                report_parts.append(f"â€¢ {suggestion['message']}")
                if "action" in suggestion:
                    report_parts.append(f"  å»ºè®®è¡ŒåŠ¨: {suggestion['action']}")

        # æ€è€ƒé—®é¢˜
        if ask_questions and analysis["questions"]:
            report_parts.append(f"\nğŸ¤” **æ€è€ƒé—®é¢˜**")
            for i, question in enumerate(analysis["questions"], 1):
                report_parts.append(f"{i}. {question}")
            report_parts.append("\nğŸ’¬ è¯·å›ç­”ä¸Šè¿°é—®é¢˜ï¼Œæˆ‘å°†æ ¹æ®æ‚¨çš„å›ç­”æä¾›æ›´å…·ä½“çš„å»ºè®®ã€‚")

        # æ€»ç»“
        if not analysis["issues"] and not analysis["suggestions"]:
            report_parts.append(f"\nâœ… **æ€»ç»“**: ä»£ç è´¨é‡è‰¯å¥½ï¼Œæœªå‘ç°æ˜æ˜¾é—®é¢˜ï¼")
        else:
            issue_count = len(analysis["issues"])
            suggestion_count = len(analysis["suggestions"])
            report_parts.append(f"\nğŸ“‹ **æ€»ç»“**: å‘ç° {issue_count} ä¸ªé—®é¢˜ï¼Œ{suggestion_count} ä¸ªæ”¹è¿›å»ºè®®")
            report_parts.append("å»ºè®®ä¼˜å…ˆå¤„ç†é«˜ä¼˜å…ˆçº§é—®é¢˜ï¼Œç„¶åè€ƒè™‘æ”¹è¿›å»ºè®®ã€‚")

        return "\n".join(report_parts)


class ProjectProgressTracker(BaseTool):
    """
    é¡¹ç›®è¿›åº¦è·Ÿè¸ªå·¥å…·
    """
    progress_file: str = "project_progress.json"
    
    def __init__(self, **kwargs):
        print("Initializing ProjectProgressTracker...")
        super().__init__(
            name="project_progress_tracker",
            description="è·Ÿè¸ªå’Œç®¡ç†è½¯ä»¶å¼€å‘é¡¹ç›®çš„è¿›åº¦",
            parameters={
                "type": "object",
                "properties": {
                    "action": {
                        "type": "string",
                        "description": "æ“ä½œç±»å‹",
                        "enum": ["create_milestone", "update_progress", "list_milestones", "add_task", "complete_task", "show_summary"]
                    },
                    "milestone_name": {
                        "type": "string",
                        "description": "é‡Œç¨‹ç¢‘åç§°"
                    },
                    "description": {
                        "type": "string",
                        "description": "æè¿°ä¿¡æ¯"
                    },
                    "task_name": {
                        "type": "string",
                        "description": "ä»»åŠ¡åç§°"
                    },
                    "progress": {
                        "type": "integer",
                        "description": "è¿›åº¦ç™¾åˆ†æ¯”(0-100)",
                        "minimum": 0,
                        "maximum": 100
                    }
                },
                "required": ["action"]
            },
            **kwargs
        )
        print("already")


    async def execute(self, action: str, **kwargs) -> str:
        """æ‰§è¡Œè¿›åº¦è·Ÿè¸ªæ“ä½œ"""
        try:
            progress_data = self._load_progress_data()

            if action == "create_milestone":
                return await self._create_milestone(progress_data, kwargs)
            elif action == "update_progress":
                return await self._update_progress(progress_data, kwargs)
            elif action == "list_milestones":
                return await self._list_milestones(progress_data)
            elif action == "add_task":
                return await self._add_task(progress_data, kwargs)
            elif action == "complete_task":
                return await self._complete_task(progress_data, kwargs)
            elif action == "show_summary":
                return await self._show_summary(progress_data)
            else:
                return f"âŒ æœªçŸ¥æ“ä½œ: {action}"

        except Exception as e:
            logger.error(f"è¿›åº¦è·Ÿè¸ªå‡ºé”™: {e}")
            return f"âŒ æ“ä½œå¤±è´¥: {str(e)}"

    def _load_progress_data(self) -> Dict:
        """åŠ è½½è¿›åº¦æ•°æ®"""
        if os.path.exists(self.progress_file):
            try:
                with open(self.progress_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except:
                pass

        # é»˜è®¤æ•°æ®ç»“æ„
        return {
            "project_name": "è½¯ä»¶å¼€å‘é¡¹ç›®",
            "created_at": datetime.now().isoformat(),
            "milestones": [],
            "tasks": [],
            "overall_progress": 0
        }

    def _save_progress_data(self, data: Dict) -> None:
        """ä¿å­˜è¿›åº¦æ•°æ®"""
        with open(self.progress_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)

    async def _create_milestone(self, data: Dict, kwargs: Dict) -> str:
        """åˆ›å»ºé‡Œç¨‹ç¢‘"""
        milestone_name = kwargs.get("milestone_name")
        description = kwargs.get("description", "")

        if not milestone_name:
            return "âŒ è¯·æä¾›é‡Œç¨‹ç¢‘åç§°"

        milestone = {
            "id": len(data["milestones"]) + 1,
            "name": milestone_name,
            "description": description,
            "created_at": datetime.now().isoformat(),
            "progress": 0,
            "status": "planning",
            "tasks": []
        }

        data["milestones"].append(milestone)
        self._save_progress_data(data)

        return f"âœ… æˆåŠŸåˆ›å»ºé‡Œç¨‹ç¢‘: {milestone_name}\nğŸ“ æè¿°: {description}"

    async def _add_task(self, data: Dict, kwargs: Dict) -> str:
        """æ·»åŠ ä»»åŠ¡"""
        task_name = kwargs.get("task_name")
        milestone_name = kwargs.get("milestone_name")
        description = kwargs.get("description", "")

        if not task_name:
            return "âŒ è¯·æä¾›ä»»åŠ¡åç§°"

        task = {
            "id": len(data["tasks"]) + 1,
            "name": task_name,
            "description": description,
            "milestone": milestone_name,
            "created_at": datetime.now().isoformat(),
            "status": "todo",
            "completed_at": None
        }

        data["tasks"].append(task)

        # å¦‚æœæŒ‡å®šäº†é‡Œç¨‹ç¢‘ï¼Œä¹Ÿæ·»åŠ åˆ°é‡Œç¨‹ç¢‘çš„ä»»åŠ¡åˆ—è¡¨
        if milestone_name:
            for milestone in data["milestones"]:
                if milestone["name"] == milestone_name:
                    milestone["tasks"].append(task["id"])
                    break

        self._save_progress_data(data)

        return f"âœ… æˆåŠŸæ·»åŠ ä»»åŠ¡: {task_name}\nğŸ“‹ å…³è”é‡Œç¨‹ç¢‘: {milestone_name or 'æ— '}"

    async def _complete_task(self, data: Dict, kwargs: Dict) -> str:
        """å®Œæˆä»»åŠ¡"""
        task_name = kwargs.get("task_name")

        if not task_name:
            return "âŒ è¯·æä¾›ä»»åŠ¡åç§°"

        task_found = False
        for task in data["tasks"]:
            if task["name"] == task_name:
                task["status"] = "completed"
                task["completed_at"] = datetime.now().isoformat()
                task_found = True
                break

        if not task_found:
            return f"âŒ æœªæ‰¾åˆ°ä»»åŠ¡: {task_name}"

        # æ›´æ–°ç›¸å…³é‡Œç¨‹ç¢‘è¿›åº¦
        self._update_milestone_progress(data)
        self._save_progress_data(data)

        return f"ğŸ‰ ä»»åŠ¡å®Œæˆ: {task_name}"

    def _update_milestone_progress(self, data: Dict) -> None:
        """æ›´æ–°é‡Œç¨‹ç¢‘è¿›åº¦"""
        for milestone in data["milestones"]:
            if milestone["tasks"]:
                completed_tasks = sum(
                    1 for task in data["tasks"]
                    if task["id"] in milestone["tasks"] and task["status"] == "completed"
                )
                total_tasks = len(milestone["tasks"])
                milestone["progress"] = int((completed_tasks / total_tasks) * 100) if total_tasks > 0 else 0

                if milestone["progress"] == 100:
                    milestone["status"] = "completed"
                elif milestone["progress"] > 0:
                    milestone["status"] = "in_progress"

        # æ›´æ–°æ•´ä½“è¿›åº¦
        if data["milestones"]:
            total_progress = sum(milestone["progress"] for milestone in data["milestones"])
            data["overall_progress"] = int(total_progress / len(data["milestones"]))

    async def _show_summary(self, data: Dict) -> str:
        """æ˜¾ç¤ºé¡¹ç›®æ€»ç»“"""
        summary_parts = []

        summary_parts.append(f"ğŸ“Š **{data['project_name']} è¿›åº¦æ€»ç»“**")
        summary_parts.append(f"ğŸ¯ æ•´ä½“è¿›åº¦: {data['overall_progress']}%")
        summary_parts.append(f"ğŸ“… åˆ›å»ºæ—¶é—´: {data['created_at'][:10]}")

        # é‡Œç¨‹ç¢‘ç»Ÿè®¡
        milestones = data["milestones"]
        if milestones:
            completed_milestones = len([m for m in milestones if m["status"] == "completed"])
            in_progress_milestones = len([m for m in milestones if m["status"] == "in_progress"])

            summary_parts.append(f"\nğŸ¯ **é‡Œç¨‹ç¢‘æ¦‚è§ˆ** (æ€»å…± {len(milestones)} ä¸ª)")
            summary_parts.append(f"âœ… å·²å®Œæˆ: {completed_milestones}")
            summary_parts.append(f"ğŸš§ è¿›è¡Œä¸­: {in_progress_milestones}")
            summary_parts.append(f"ğŸ“‹ è®¡åˆ’ä¸­: {len(milestones) - completed_milestones - in_progress_milestones}")

        # ä»»åŠ¡ç»Ÿè®¡
        tasks = data["tasks"]
        if tasks:
            completed_tasks = len([t for t in tasks if t["status"] == "completed"])
            summary_parts.append(f"\nğŸ“ **ä»»åŠ¡æ¦‚è§ˆ** (æ€»å…± {len(tasks)} ä¸ª)")
            summary_parts.append(f"âœ… å·²å®Œæˆ: {completed_tasks}")
            summary_parts.append(f"ğŸ“‹ å¾…å®Œæˆ: {len(tasks) - completed_tasks}")

        # æœ€è¿‘æ´»åŠ¨
        recent_tasks = sorted(
            [t for t in tasks if t.get("completed_at")],
            key=lambda x: x["completed_at"],
            reverse=True
        )[:3]

        if recent_tasks:
            summary_parts.append(f"\nğŸ•’ **æœ€è¿‘å®Œæˆçš„ä»»åŠ¡**")
            for task in recent_tasks:
                completed_date = task["completed_at"][:10]
                summary_parts.append(f"â€¢ {task['name']} ({completed_date})")

        return "\n".join(summary_parts)

    async def _list_milestones(self, data: Dict) -> str:
        """åˆ—å‡ºæ‰€æœ‰é‡Œç¨‹ç¢‘"""
        milestones = data["milestones"]

        if not milestones:
            return "ğŸ“‹ å½“å‰æ²¡æœ‰åˆ›å»ºä»»ä½•é‡Œç¨‹ç¢‘\nğŸ’¡ ä½¿ç”¨ create_milestone æ“ä½œæ¥åˆ›å»ºç¬¬ä¸€ä¸ªé‡Œç¨‹ç¢‘"

        milestone_list = [f"ğŸ¯ **é¡¹ç›®é‡Œç¨‹ç¢‘** (å…± {len(milestones)} ä¸ª)"]

        for milestone in milestones:
            status_emoji = {
                "planning": "ğŸ“‹",
                "in_progress": "ğŸš§",
                "completed": "âœ…"
            }.get(milestone["status"], "â“")

            milestone_list.append(f"\n{status_emoji} **{milestone['name']}** ({milestone['progress']}%)")
            if milestone["description"]:
                milestone_list.append(f"   ğŸ“ {milestone['description']}")

            # æ˜¾ç¤ºå…³è”ä»»åŠ¡
            milestone_tasks = [
                task for task in data["tasks"]
                if task["id"] in milestone.get("tasks", [])
            ]
            if milestone_tasks:
                completed_count = len([t for t in milestone_tasks if t["status"] == "completed"])
                milestone_list.append(f"   ğŸ“Š ä»»åŠ¡è¿›åº¦: {completed_count}/{len(milestone_tasks)}")

        return "\n".join(milestone_list)


class RequirementClarifier(BaseTool):
    """
    éœ€æ±‚æ¾„æ¸…å·¥å…·
    """

    def __init__(self):
        super().__init__(
            name="requirement_clarifier",
            description="æ™ºèƒ½åˆ†æå’Œæ¾„æ¸…è½¯ä»¶å¼€å‘éœ€æ±‚",
            parameters={
                "type": "object",
                "properties": {
                    "user_requirement": {
                        "type": "string",
                        "description": "ç”¨æˆ·åŸå§‹éœ€æ±‚æè¿°"
                    },
                    "analysis_depth": {
                        "type": "string",
                        "description": "åˆ†ææ·±åº¦",
                        "enum": ["basic", "detailed", "comprehensive"],
                        "default": "detailed"
                    }
                },
                "required": ["user_requirement"]
            }
        )

    async def execute(self, user_requirement: str, analysis_depth: str = "detailed") -> str:
        """æ‰§è¡Œéœ€æ±‚æ¾„æ¸…"""
        try:
            # åˆ†æéœ€æ±‚
            analysis = self._analyze_requirement(user_requirement, analysis_depth)

            # ç”Ÿæˆæ¾„æ¸…é—®é¢˜
            clarification_questions = self._generate_clarification_questions(analysis)

            # ç”ŸæˆæŠ¥å‘Š
            report = self._generate_clarification_report(analysis, clarification_questions)

            return f"ğŸ” éœ€æ±‚åˆ†æå®Œæˆ\n\n{report}"

        except Exception as e:
            logger.error(f"éœ€æ±‚æ¾„æ¸…å‡ºé”™: {e}")
            return f"âŒ éœ€æ±‚æ¾„æ¸…å¤±è´¥: {str(e)}"

    def _analyze_requirement(self, requirement: str, depth: str) -> Dict[str, Any]:
        """åˆ†æç”¨æˆ·éœ€æ±‚"""
        words = requirement.lower().split()

        analysis = {
            "original_requirement": requirement,
            "key_concepts": [],
            "technology_hints": [],
            "functional_areas": [],
            "ambiguous_parts": [],
            "missing_details": [],
            "complexity_level": "medium"
        }

        # è¯†åˆ«å…³é”®æ¦‚å¿µ
        tech_keywords = {
            "web": ["ç½‘ç«™", "web", "ç½‘é¡µ", "å‰ç«¯", "åç«¯"],
            "mobile": ["æ‰‹æœº", "ç§»åŠ¨", "app", "å®‰å“", "ios"],
            "data": ["æ•°æ®", "æ•°æ®åº“", "åˆ†æ", "ç»Ÿè®¡", "æŠ¥è¡¨"],
            "ai": ["äººå·¥æ™ºèƒ½", "ai", "æœºå™¨å­¦ä¹ ", "æ·±åº¦å­¦ä¹ ", "æ™ºèƒ½"],
            "api": ["æ¥å£", "api", "æœåŠ¡", "è°ƒç”¨"],
            "game": ["æ¸¸æˆ", "æ¸¸æˆå¼€å‘", "unity", "å¼•æ“"]
        }

        for category, keywords in tech_keywords.items():
            if any(keyword in requirement for keyword in keywords):
                analysis["technology_hints"].append(category)

        # è¯†åˆ«åŠŸèƒ½é¢†åŸŸ
        functional_keywords = {
            "user_management": ["ç”¨æˆ·", "ç™»å½•", "æ³¨å†Œ", "è´¦å·"],
            "data_processing": ["å¤„ç†", "è®¡ç®—", "ç®—æ³•", "é€»è¾‘"],
            "ui_ux": ["ç•Œé¢", "äº¤äº’", "ç”¨æˆ·ä½“éªŒ", "è®¾è®¡"],
            "integration": ["é›†æˆ", "å¯¹æ¥", "è¿æ¥", "åŒæ­¥"],
            "automation": ["è‡ªåŠ¨", "å®šæ—¶", "æ‰¹å¤„ç†", "ä»»åŠ¡"]
        }

        for area, keywords in functional_keywords.items():
            if any(keyword in requirement for keyword in keywords):
                analysis["functional_areas"].append(area)

        # æ£€æµ‹æ¨¡ç³Šéƒ¨åˆ†
        ambiguous_indicators = ["ç±»ä¼¼", "å·®ä¸å¤š", "ç®€å•çš„", "å¤æ‚çš„", "å¥½çœ‹çš„", "é«˜æ€§èƒ½"]
        for indicator in ambiguous_indicators:
            if indicator in requirement:
                analysis["ambiguous_parts"].append(f"'{indicator}' éœ€è¦æ›´å…·ä½“çš„å®šä¹‰")

        # è¯„ä¼°å¤æ‚åº¦
        complexity_indicators = {
            "simple": ["ç®€å•", "åŸºç¡€", "å°", "demo"],
            "complex": ["å¤æ‚", "é«˜çº§", "å¤§å‹", "ä¼ä¸šçº§", "åˆ†å¸ƒå¼", "å¾®æœåŠ¡"]
        }

        if any(word in requirement for word in complexity_indicators["simple"]):
            analysis["complexity_level"] = "simple"
        elif any(word in requirement for word in complexity_indicators["complex"]):
            analysis["complexity_level"] = "complex"

        return analysis

    def _generate_clarification_questions(self, analysis: Dict) -> List[Dict[str, str]]:
        """ç”Ÿæˆæ¾„æ¸…é—®é¢˜"""
        questions = []

        # åŸºäºæŠ€æœ¯æ–¹å‘çš„é—®é¢˜
        if "web" in analysis["technology_hints"]:
            questions.append({
                "category": "æŠ€æœ¯é€‰å‹",
                "question": "æ‚¨å¸Œæœ›å¼€å‘ä»€ä¹ˆç±»å‹çš„Webåº”ç”¨ï¼Ÿ(é™æ€ç½‘ç«™ã€åŠ¨æ€Webåº”ç”¨ã€SPAå•é¡µåº”ç”¨)",
                "why": "ä¸åŒç±»å‹çš„Webåº”ç”¨éœ€è¦ä¸åŒçš„æŠ€æœ¯æ ˆå’Œæ¶æ„è®¾è®¡"
            })

        if "mobile" in analysis["technology_hints"]:
            questions.append({
                "category": "å¹³å°é€‰æ‹©",
                "question": "æ‚¨å¸Œæœ›æ”¯æŒå“ªäº›ç§»åŠ¨å¹³å°ï¼Ÿ(iOSã€Androidã€è¿˜æ˜¯è·¨å¹³å°)",
                "why": "å¹³å°é€‰æ‹©ä¼šå½±å“å¼€å‘å·¥å…·å’ŒæŠ€æœ¯æ ˆçš„é€‰æ‹©"
            })

        # åŸºäºåŠŸèƒ½é¢†åŸŸçš„é—®é¢˜
        if "user_management" in analysis["functional_areas"]:
            questions.append({
                "category": "ç”¨æˆ·ç®¡ç†",
                "question": "ç”¨æˆ·ç®¡ç†éœ€è¦å“ªäº›å…·ä½“åŠŸèƒ½ï¼Ÿ(æ³¨å†Œæ–¹å¼ã€æƒé™ç­‰çº§ã€ä¸ªäººèµ„æ–™ç­‰)",
                "why": "ç”¨æˆ·ç®¡ç†çš„å¤æ‚ç¨‹åº¦ä¼šå½±å“æ•°æ®åº“è®¾è®¡å’Œå®‰å…¨æ¶æ„"
            })

        if "data_processing" in analysis["functional_areas"]:
            questions.append({
                "category": "æ•°æ®å¤„ç†",
                "question": "éœ€è¦å¤„ç†ä»€ä¹ˆç±»å‹çš„æ•°æ®ï¼Ÿæ•°æ®é‡å¤§æ¦‚æœ‰å¤šå°‘ï¼Ÿ",
                "why": "æ•°æ®ç±»å‹å’Œè§„æ¨¡ä¼šå½±å“å­˜å‚¨æ–¹æ¡ˆå’Œå¤„ç†æ¶æ„çš„é€‰æ‹©"
            })

        # åŸºäºæ¨¡ç³Šéƒ¨åˆ†çš„é—®é¢˜
        if analysis["ambiguous_parts"]:
            questions.append({
                "category": "éœ€æ±‚æ¾„æ¸…",
                "question": "èƒ½å¦å…·ä½“è¯´æ˜ä»¥ä¸‹è¡¨è¿°ï¼Ÿ" + "ã€".join(analysis["ambiguous_parts"]),
                "why": "æ˜ç¡®éœ€æ±‚ç»†èŠ‚æœ‰åŠ©äºå‡†ç¡®ä¼°ç®—å·¥ä½œé‡å’Œé€‰æ‹©åˆé€‚æ–¹æ¡ˆ"
            })

        # é€šç”¨é—®é¢˜
        questions.extend([
            {
                "category": "é¡¹ç›®èƒŒæ™¯",
                "question": "è¿™ä¸ªé¡¹ç›®çš„ä¸»è¦ç”¨æˆ·ç¾¤ä½“æ˜¯è°ï¼Ÿé¢„æœŸä½¿ç”¨åœºæ™¯æ˜¯ä»€ä¹ˆï¼Ÿ",
                "why": "äº†è§£ç”¨æˆ·ç¾¤ä½“æœ‰åŠ©äºåšå‡ºæ›´å¥½çš„è®¾è®¡å†³ç­–"
            },
            {
                "category": "æŠ€æœ¯çº¦æŸ",
                "question": "æœ‰ä»€ä¹ˆæŠ€æœ¯é™åˆ¶æˆ–åå¥½å—ï¼Ÿ(ç¼–ç¨‹è¯­è¨€ã€æ¡†æ¶ã€éƒ¨ç½²ç¯å¢ƒç­‰)",
                "why": "æŠ€æœ¯çº¦æŸä¼šå½±å“æ–¹æ¡ˆè®¾è®¡å’Œå®ç°æ–¹å¼"
            },
            {
                "category": "é¡¹ç›®èŒƒå›´",
                "question": "é¡¹ç›®çš„ä¼˜å…ˆçº§å¦‚ä½•ï¼Ÿå“ªäº›åŠŸèƒ½æ˜¯æ ¸å¿ƒå¿…é¡»çš„ï¼Œå“ªäº›æ˜¯å¯é€‰çš„ï¼Ÿ",
                "why": "æ˜ç¡®ä¼˜å…ˆçº§æœ‰åŠ©äºåˆç†è§„åˆ’å¼€å‘é¡ºåºå’Œèµ„æºåˆ†é…"
            }
        ])

        return questions[:6]  # é™åˆ¶é—®é¢˜æ•°é‡ï¼Œé¿å…è¿‡å¤š

    def _generate_clarification_report(self, analysis: Dict, questions: List[Dict]) -> str:
        """ç”Ÿæˆæ¾„æ¸…æŠ¥å‘Š"""
        report_parts = []

        # éœ€æ±‚ç†è§£
        report_parts.append("ğŸ“‹ **éœ€æ±‚ç†è§£**")
        report_parts.append(f"åŸå§‹éœ€æ±‚: {analysis['original_requirement']}")

        if analysis["technology_hints"]:
            report_parts.append(f"æŠ€æœ¯æ–¹å‘: {', '.join(analysis['technology_hints'])}")

        if analysis["functional_areas"]:
            report_parts.append(f"åŠŸèƒ½é¢†åŸŸ: {', '.join(analysis['functional_areas'])}")

        report_parts.append(f"å¤æ‚åº¦è¯„ä¼°: {analysis['complexity_level']}")

        # æ¾„æ¸…é—®é¢˜
        report_parts.append(f"\nâ“ **éœ€è¦æ¾„æ¸…çš„é—®é¢˜** (å…±{len(questions)}ä¸ª)")

        for i, q in enumerate(questions, 1):
            report_parts.append(f"\n**é—®é¢˜ {i}: {q['category']}**")
            report_parts.append(f"ğŸ¤” {q['question']}")
            report_parts.append(f"ğŸ’¡ åŸå› : {q['why']}")

        # ä¸‹ä¸€æ­¥å»ºè®®
        report_parts.append(f"\nğŸ¯ **å»ºè®®çš„ä¸‹ä¸€æ­¥**")
        report_parts.append("1. è¯·å›ç­”ä¸Šè¿°é—®é¢˜ï¼Œæˆ‘å°†æ ¹æ®æ‚¨çš„å›ç­”åˆ¶å®šå…·ä½“çš„æŠ€æœ¯æ–¹æ¡ˆ")
        report_parts.append("2. å¦‚æœéœ€è¦ï¼Œæˆ‘å¯ä»¥å¸®æ‚¨åˆ›å»ºé¡¹ç›®é‡Œç¨‹ç¢‘å’Œä»»åŠ¡åˆ†è§£")
        report_parts.append("3. ç¡®å®šæŠ€æœ¯æ–¹æ¡ˆåï¼Œæˆ‘ä»¬å¯ä»¥å¼€å§‹å…·ä½“çš„å¼€å‘å·¥ä½œ")

        return "\n".join(report_parts)
